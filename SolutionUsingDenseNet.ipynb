{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a05e7329",
   "metadata": {},
   "source": [
    "# Solution using a DenseNet\n",
    "Solution by Luca Lanzo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777c7cfe",
   "metadata": {},
   "source": [
    "### Problem description\n",
    "The classification of the Fashion-MNIST dataset is also a good opportunity to test out a DenseNet architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5fab45",
   "metadata": {},
   "source": [
    "### Proposed solution\n",
    "Use the standard Fashion-MNIST dataset from the torchvision library to train a model able to classify the images by their type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4250e024",
   "metadata": {},
   "source": [
    "## Coded Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd0e1b8",
   "metadata": {},
   "source": [
    "### Step 1: Importing all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47fce87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b9ee3f",
   "metadata": {},
   "source": [
    "### Step 2: Setup CUDA for parallel computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d2c6d1",
   "metadata": {},
   "source": [
    "While the sequential computations run on the CPU, Pytorch can offload the heavy duty parallel computations onto the GPU.\n",
    "Not every user running this notebook has CUDA enabled so I have coded a short device check which creates the data and the model either on CUDA or CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a48bbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: True\n"
     ]
    }
   ],
   "source": [
    "print(f'Cuda available: {torch.cuda.is_available()}')\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7ae1d3",
   "metadata": {},
   "source": [
    "### Step 3: Get the Fashion-MNIST train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a893fed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = datasets.FashionMNIST(root='datasets', train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_test = datasets.FashionMNIST(root='datasets', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d2cc39",
   "metadata": {},
   "source": [
    "### Step 4: Instantiate the DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7b105d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "trainloader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9625d0c5",
   "metadata": {},
   "source": [
    "### Step 5: Defining the CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f348de9",
   "metadata": {},
   "source": [
    "#### Step 5.1: Defining the DenseLayer\n",
    "It is important to add zero-padding to the convolutional layer in order to preserve the spatial dimension of the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "718a4a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.bn = nn.BatchNorm2d(in_channels)\n",
    "        # Kernel size fixed to 3x3\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding='same')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dac4aa",
   "metadata": {},
   "source": [
    "#### Step 5.2: Defining the DenseBlock\n",
    "I thought out the following loop to program the DenseBlock architecture. On init the code will create a variable amount of DenseLayers each with increasing channel sizes. On forward, it iterates through the DenseLayers and runs the Layer. After it the result gets concatenated to the previous DenseLayer-results. It follows this model:  \n",
    "$$\\mathcal{x_l = H_l ([x_0, x_1,  ... , x_{l-1}])}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "539b358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, num_layers, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.layers = []\n",
    "        \n",
    "        for _ in range(num_layers):\n",
    "            self.layers.append(DenseLayer(in_channels, out_channels).to(device))\n",
    "            \n",
    "            # The channel size will double with each concat\n",
    "            in_channels *= 2\n",
    "            out_channels *= 2\n",
    "    \n",
    "    def forward(self, x):\n",
    "        concat = x\n",
    "        out = None\n",
    "        \n",
    "        for dense_layer in self.layers:\n",
    "            \n",
    "            out = dense_layer(concat)\n",
    "            concat = torch.cat((concat, out), 1)\n",
    "        \n",
    "        return concat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af61035e",
   "metadata": {},
   "source": [
    "#### Step 5.3: Defining the DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77d2eeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3)\n",
    "        self.ap1 = nn.AvgPool2d(kernel_size=1, stride=2)\n",
    "        \n",
    "        self.db1 = DenseBlock(num_layers=3, in_channels=4, out_channels=4).to(device)\n",
    "        \n",
    "        # Transition layer\n",
    "        # The channel dimension gets blown up from 4 to 16 because it doubles after every concatenation (4 to 8 to 16)\n",
    "        self.bn = nn.BatchNorm2d(num_features=16)    \n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=4, kernel_size=1)\n",
    "        self.ap2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.db2 = DenseBlock(num_layers=3, in_channels=4, out_channels=4).to(device)\n",
    "        \n",
    "        # https://discuss.pytorch.org/t/global-average-pooling-in-pytorch/6721/4?page=2\n",
    "        # \"To do this you can apply ... nn.AvgPool2d ... with kernel_size equal to the dimensions of the feature maps.\"\n",
    "        # Dimension of the feature maps is at this point 6x6\n",
    "        # self.ap3 = nn.AvgPool2d((6,6))\n",
    "        \n",
    "        self.f = nn.Flatten()\n",
    "\n",
    "        self.fc = nn.Linear(576, 10)      \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # pre\n",
    "        x = self.ap1(self.conv1(x))\n",
    "        \n",
    "        # first DenseBlock\n",
    "        x = self.db1(x)\n",
    "        \n",
    "        # transition layer\n",
    "        x = self.ap2(self.conv2(self.bn(x)))\n",
    "        \n",
    "        # second Denseblock\n",
    "        x = self.db2(x)\n",
    "        \n",
    "        # global average pooling\n",
    "        # I couldn't get my model to work with this. I am not sure what i did wrong, or maybe I misunderstood Global\n",
    "        # Average Pooling...\n",
    "        # x = self.ap3(x)\n",
    "        \n",
    "        # fully connected layer\n",
    "        x = self.f(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069d428e",
   "metadata": {},
   "source": [
    "#### Step 5.4: Initialise the model and transfer to GPU if possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0902c5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (conv1): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (ap1): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
       "  (db1): DenseBlock()\n",
       "  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (ap2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (db2): DenseBlock()\n",
       "  (f): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc): Linear(in_features=576, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DenseNet()\n",
    "\n",
    "# send the model to CUDA\n",
    "model.to(device)\n",
    "# print(f'Model has been transferred to CUDA: {next(model.parameters()).is_cuda}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b69a6fb",
   "metadata": {},
   "source": [
    "#### Step 5.5: Some questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d272988",
   "metadata": {},
   "source": [
    "**What is the spatial dimension of the first DenseBlock and how many input channels and output channels does it have?**  \n",
    "The spatial dimensions are 13 x 13.\n",
    "The channels are 4 before and 64 after the block.\n",
    "\n",
    "**What is the spatial dimension of the second DenseBlock?**  \n",
    "The spatial dimensions are 16 x 16.\n",
    "\n",
    "\n",
    "**What dimension is the input into the final FC layer?**  \n",
    "The dimension is 6 x 6 before flattening and after the FC layer gets a 576 long vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adfd505",
   "metadata": {},
   "source": [
    "### Step 6: Define the loss function\n",
    "The loss function is defined as the cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbb43098",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba154d87",
   "metadata": {},
   "source": [
    "### Step 7: Define the optimisation algorithm\n",
    "The optimisation algorithm is defined as the SGD algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e6d557c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a868bc",
   "metadata": {},
   "source": [
    "### Step 8: Model training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08a9ec44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(trainloader, model, loss_func, optimiser):\n",
    "    num_epochs = 100 # tweak for optimisation\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0\n",
    "        for i, (images, labels) in enumerate(trainloader):\n",
    "            # transfer data to GPU\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # training pass\n",
    "            optimiser.zero_grad()\n",
    "            \n",
    "            # get predictions\n",
    "            output = model(images)\n",
    "            \n",
    "            # get loss value\n",
    "            loss = loss_func(output, labels)\n",
    "            \n",
    "            # go in the direction opposite of the gradient\n",
    "            loss.backward()\n",
    "            \n",
    "            # update parameter values\n",
    "            optimiser.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        losses.append(running_loss/i)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs} --- Loss {running_loss/i}')\n",
    "        \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96af098c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 --- Loss 1.3477188667171023\n",
      "Epoch 2/100 --- Loss 0.8243412766446415\n",
      "Epoch 3/100 --- Loss 0.7272820726164386\n",
      "Epoch 4/100 --- Loss 0.6815428147331263\n",
      "Epoch 5/100 --- Loss 0.6524777266586947\n",
      "Epoch 6/100 --- Loss 0.6302472242178061\n",
      "Epoch 7/100 --- Loss 0.6132664836497388\n",
      "Epoch 8/100 --- Loss 0.5981381617040715\n",
      "Epoch 9/100 --- Loss 0.5866408160226977\n",
      "Epoch 10/100 --- Loss 0.5755980991654925\n",
      "Epoch 11/100 --- Loss 0.5662113261910585\n",
      "Epoch 12/100 --- Loss 0.5572526456835942\n",
      "Epoch 13/100 --- Loss 0.549684611395893\n",
      "Epoch 14/100 --- Loss 0.5431421681219696\n",
      "Epoch 15/100 --- Loss 0.5369734949408433\n",
      "Epoch 16/100 --- Loss 0.5312277175422407\n",
      "Epoch 17/100 --- Loss 0.526281042995616\n",
      "Epoch 18/100 --- Loss 0.5211050123867825\n",
      "Epoch 19/100 --- Loss 0.5175753500726488\n",
      "Epoch 20/100 --- Loss 0.5129472721590955\n",
      "Epoch 21/100 --- Loss 0.5097024098802836\n",
      "Epoch 22/100 --- Loss 0.5059092652976004\n",
      "Epoch 23/100 --- Loss 0.5021208451471777\n",
      "Epoch 24/100 --- Loss 0.4997178917893997\n",
      "Epoch 25/100 --- Loss 0.49609641469696647\n",
      "Epoch 26/100 --- Loss 0.49355657373228645\n",
      "Epoch 27/100 --- Loss 0.4914316804999979\n",
      "Epoch 28/100 --- Loss 0.4889399616891502\n",
      "Epoch 29/100 --- Loss 0.48686114316567397\n",
      "Epoch 30/100 --- Loss 0.4842947178289422\n",
      "Epoch 31/100 --- Loss 0.4827837188783874\n",
      "Epoch 32/100 --- Loss 0.4810735591583782\n",
      "Epoch 33/100 --- Loss 0.47924143470760083\n",
      "Epoch 34/100 --- Loss 0.47739429943836653\n",
      "Epoch 35/100 --- Loss 0.4748779208614276\n",
      "Epoch 36/100 --- Loss 0.47390301360024345\n",
      "Epoch 37/100 --- Loss 0.4719437277342519\n",
      "Epoch 38/100 --- Loss 0.4708105307868403\n",
      "Epoch 39/100 --- Loss 0.4694485314763509\n",
      "Epoch 40/100 --- Loss 0.4676592242386606\n",
      "Epoch 41/100 --- Loss 0.46656409020607287\n",
      "Epoch 42/100 --- Loss 0.4651566055468005\n",
      "Epoch 43/100 --- Loss 0.46386942146425575\n",
      "Epoch 44/100 --- Loss 0.4625816113419003\n",
      "Epoch 45/100 --- Loss 0.4620037197939351\n",
      "Epoch 46/100 --- Loss 0.46064076795537245\n",
      "Epoch 47/100 --- Loss 0.4594608019305091\n",
      "Epoch 48/100 --- Loss 0.45800279774981684\n",
      "Epoch 49/100 --- Loss 0.45701469659295857\n",
      "Epoch 50/100 --- Loss 0.45592005932942414\n",
      "Epoch 51/100 --- Loss 0.4556330862080949\n",
      "Epoch 52/100 --- Loss 0.4539979150534695\n",
      "Epoch 53/100 --- Loss 0.45280374319125444\n",
      "Epoch 54/100 --- Loss 0.45208244796237373\n",
      "Epoch 55/100 --- Loss 0.4518698942330148\n",
      "Epoch 56/100 --- Loss 0.4505228750471376\n",
      "Epoch 57/100 --- Loss 0.449620831089142\n",
      "Epoch 58/100 --- Loss 0.44853451777981895\n",
      "Epoch 59/100 --- Loss 0.4475139123825436\n",
      "Epoch 60/100 --- Loss 0.4474540903654873\n",
      "Epoch 61/100 --- Loss 0.44688178898177594\n",
      "Epoch 62/100 --- Loss 0.44569295020694405\n",
      "Epoch 63/100 --- Loss 0.4451641864819914\n",
      "Epoch 64/100 --- Loss 0.444711633790762\n",
      "Epoch 65/100 --- Loss 0.44302816103156817\n",
      "Epoch 66/100 --- Loss 0.4427994307862897\n",
      "Epoch 67/100 --- Loss 0.4421746108967524\n",
      "Epoch 68/100 --- Loss 0.44144596496963096\n",
      "Epoch 69/100 --- Loss 0.4405548384683764\n",
      "Epoch 70/100 --- Loss 0.4400787911353967\n",
      "Epoch 71/100 --- Loss 0.43930894919694996\n",
      "Epoch 72/100 --- Loss 0.4387094921344875\n",
      "Epoch 73/100 --- Loss 0.43829776652348346\n",
      "Epoch 74/100 --- Loss 0.4378390060339728\n",
      "Epoch 75/100 --- Loss 0.4371585098978801\n",
      "Epoch 76/100 --- Loss 0.43618518961036307\n",
      "Epoch 77/100 --- Loss 0.4357148577960638\n",
      "Epoch 78/100 --- Loss 0.43487361818552017\n",
      "Epoch 79/100 --- Loss 0.4346296931815963\n",
      "Epoch 80/100 --- Loss 0.43457998239841217\n",
      "Epoch 81/100 --- Loss 0.4333893252998336\n",
      "Epoch 82/100 --- Loss 0.43295127280756956\n",
      "Epoch 83/100 --- Loss 0.43252237863902354\n",
      "Epoch 84/100 --- Loss 0.4317460727487874\n",
      "Epoch 85/100 --- Loss 0.43173143095695055\n",
      "Epoch 86/100 --- Loss 0.4317079891697464\n",
      "Epoch 87/100 --- Loss 0.4306396645231125\n",
      "Epoch 88/100 --- Loss 0.4300243796573745\n",
      "Epoch 89/100 --- Loss 0.4295202378088083\n",
      "Epoch 90/100 --- Loss 0.429098242877895\n",
      "Epoch 91/100 --- Loss 0.4290001323589912\n",
      "Epoch 92/100 --- Loss 0.42824522998088443\n",
      "Epoch 93/100 --- Loss 0.42752166028715605\n",
      "Epoch 94/100 --- Loss 0.42747614946630264\n",
      "Epoch 95/100 --- Loss 0.42662300398716557\n",
      "Epoch 96/100 --- Loss 0.42637996222728336\n",
      "Epoch 97/100 --- Loss 0.4263264772474256\n",
      "Epoch 98/100 --- Loss 0.4256420534772751\n",
      "Epoch 99/100 --- Loss 0.4251480802384197\n",
      "Epoch 100/100 --- Loss 0.4245027313884507\n"
     ]
    }
   ],
   "source": [
    "losses = model_training(trainloader, model, loss_func, optimiser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f09ae13a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16b9d642640>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the losses after finishing the training\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5641d81",
   "metadata": {},
   "source": [
    "### Step 10: Check the overall performance on all test images\n",
    "Important: The model has to be set to evaluation mode in order to turn off Dropout and BatchNorm (and other layers/parts of the model). Just to try it out I left the model on CUDA and tested it like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0808cec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model on all test images is 83.6 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'The accuracy of the model on all test images is {100 * correct / total} %')\n",
    "\n",
    "if ((100 * correct / total) > 85):\n",
    "    plt.imshow(plt.imread('important_reaction_picture.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff916bb7",
   "metadata": {},
   "source": [
    "### Step 11: Evaluating the model and the performanceÂ¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d7b44f",
   "metadata": {},
   "source": [
    "Here are my results using the DenseNet:   \n",
    "\n",
    "\n",
    "_lr=0.1, epochs=30, batch_size=128_  \n",
    "I got a 85.01 % accuracy. This is quite good but I am going to let it run for some more epochs and decrease the learning rate\n",
    "\n",
    "_**lr=0.01**, **epochs=100**, batch_size=128_   \n",
    "83,6 %. This actually got a worse accuracy, so I will stick with a 0.1 learning rate.\n",
    "\n",
    "\n",
    "---\n",
    "I will stop this a bit sooner than on the other solution (with ResBlocks), as I don't think I can get any better results if I let it run any longer :) \n",
    "I choose the following hyper parameters for my model:  \n",
    "**lr=0.1, epochs=100, batch_size=128**: This will yield a good result with which I am content."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
